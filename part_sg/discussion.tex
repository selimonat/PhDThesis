

We measured EEG in 24 subjects while they viewed rotating Gabor patches and
listened to frequency-modulated tones. Our results reveal two forms of
stimulus locking of EEG to the temporal dynamics of visual stimuli, evident
from changes in EEG power over time and from the temporal structure of the
EEG waveform. Auditory stimuli presented alone do not lead to any
measurable, structured changes in EEG power or waveform. However, analysis
of bimodal trials shows that visual stimulus locking is modulated by the
temporal congruence of simultaneous auditory input \textemdash locking of
EEG waveforms to visual stimuli was reduced when the auditory input
mismatched the temporal profile of the visual input. Furthermore, this
multisensory interaction became even clearer when the time course of
waveform locking was examined. Under congruent bimodal stimulation
conditions, visual stimulus locking increased steadily over the duration of
the trial, while the incongruent bimodal condition showed no such effect.
Thus we suggest that stimulus locking is a suitable tool for studying and
characterising the multisensory processing of dynamically changing auditory
and visual stimuli.



In order to explore the importance of extended dynamic modulation of
auditory and visual stimuli, we required a relatively long trial duration.
This raised the need for a task to ensure participants' attention was
maintained. We decided on a task that required attention to both stimulus
components in parallel \textemdash to decide whether the auditory and
visual signals matched \textemdash rather than directing the subject to
focus on a single sensory modality. As a result, the task could not be
directly transferred to single unimodal components of the audiovisual
stimuli, and was instead applied to sequentially presented pairs of
components from either modality.  The simultaneous and sequential
comparison of stimulus dynamics constitutes two different tasks and
necessitates a careful comparison of unimodal and bimodal conditions.
However, the task allows us to be confident of subjects' attentiveness
during the experiment.



Here, as a first step, we report results for signals measured at
electrodes, i.e. in sensor space. An EEG signal is a combination of signals
from different cortical sources and noise. It would be desirable to further
process the data in order to translate our findings into source space by
performing a source localisation that would attempt to isolate the location
and activity of the cortical sources involved. However, this requires
additional assumptions and currently there is no available method
that\textemdash is generally accepted and free of problems
\citep{nunez1981a}. An additional issue is that algorithms for source
localization make assumptions about the interaction or independence of
different signals.  Work is still under way to develop synchrony measures
in source space \citep[e.g.][]{marzetti2008a}. Although our results do not
rely on a spatial interpretation, we do make some tentative assumptions
here: that EEG measured at occipital channels captures activation in early
visual areas proximal to these measurement sites, whereas effects we find
at centro-parietal electrodes reflect cortical processing at some higher
stages. A more detailed investigation of the cortical sources of the
stimulus locking phenomena described here must be left to future work. 



We did not see any evidence for stimulus locking to auditory stimuli, or to
the auditory component of audiovisual stimuli. This is surprising, as it is
commonly assumed that the temporal reliability of the auditory system is
higher than the visual. As a consequence, its contribution in optimal
sensory fusion is high for temporal estimates
\citep[e.g.][]{bresciani2008a} and small for spatial estimates
\citep[e.g.][]{Kording2007a}.  In addition, the modulation of brain
responses to changes in amplitude or frequency of simple auditory stimuli
is a well-established phenomenon.  Auditory entrainment has been optimally
found in response to 40 Hz auditory stimulation \citep{galambos1981a}, but
has also been reported at lower frequencies \citep[e.g.][]{ding2006a}. A
systematic examination of the steady-state response to sinusoidal frequency
modulation by \cite{picton1987a} found that for lower modulation
frequencies, responses were most reliable between 3 and 7 Hz. The amplitude
and phase of responses to tones modulated at the rates of change used in
our study were not found to be significantly reliable, and thus it may
simply be the case that the auditory stimuli used here change too slowly.
Indeed, preliminary results of current work with 3 Hz frequency modulation
have shown a tendency to a locking of 40 Hz power to the dynamics of the
auditory stimulus.



We applied two analysis approaches to investigate how the dynamics of the
stimulus are reflected in the power and phase of the measured EEG signals,
respectively. The first approach, spectrotemporal analysis, correlates
power changes with stimulus speed, and can reveal locking of EEG power
changes to stimulus dynamics at frequencies beyond the rate of change of
the stimulus. The second approach, waveform analysis, correlates ERP
waveforms with stimulus speed, and thus mirrors a stable phase-relationship
between EEG signals and the time-course of the stimulus. Due to the use of
correlation, the entrainment we observe for the EEG waveform must result
from the phase-locking of frequencies within the range contained in the
stimulus speed. Previously, locking of LFP power to dynamic visual
stimulation has been investigated in cat visual cortex \citep{kayser2004b}
using the same spectrotemporal locking analysis. In addition, entrainment
or phase-locking of neural responses to regularly repeating stimuli has
been extensively studied \citep[e.g.][]{rager1998a} and this steady-state
cortical response has been used to investigate many other phenomena,
especially attention \citep[e.g.][]{muller2003a}. Our analysis approaches
are in line with both kinds of locking mechanisms, but are applied here to
explore stimulus locking of human EEG to continuously, irregularly changing
visual stimuli. 



Our spectrotemporal approach investigated locking to all frequencies
between 0 and 100 Hz. Within this range, different frequency bands have
been defined, including delta (0.5-4 Hz), theta (4-8 Hz), alpha (8-13 Hz),
beta (13-30 Hz), and gamma (> 30 Hz) and these bands have been suggested to
reflect different functionalities (see \cite{steriade1990a} for an early
review).  We found two instances of spectrotemporal locking that are
centred at distinct frequencies (20-30 and 8-20 Hz) and furthermore differ
in correlation lag and direction of effect. As such, we suggest that we are
dealing with two distinct spectrotemporal locking processes with different
functional significance.



The first effect found was that induced power changes in the beta (20-30
Hz) range lock to the speed profile of visual input with a lag of 92 ms.
This is in agreement with previous results that found locking between 20-35
Hz at around 100 ms lag in cat visual cortex \citep{kayser2004b}.
Curiously, the frequency showing the strongest locking in our results is
close to 25 Hz, which is exactly the frame rate at which our movies were
created, but is far from the refresh rate of the monitor (100 Hz).
However, it is not clear whether the correspondence with the frame rate is
simply coincidental or not, which brings into question the functional
significance of the 20-30 Hz band. There is a crucial difference between
our study and the earlier work in cats \textemdash humans have a
comparatively lower flicker fusion frequency than cat, so the 25 Hz frame
rate can be considered to be adequate for human viewers. Although we have
clearly found evidence for spectrotemporal locking to irregular visual
stimulation, we cannot generalise this finding to more natural conditions. 



The second effect revealed by the spectrotemporal anaylsis was an
anti-correlation in a broad alpha band (8-20 Hz). The human occipital alpha
rhythm has traditionally been associated with a state of cortical rest, as
put forward by the idling hypothesis. More recent studies have extended the
idling hypothesis, proposing that a strong alpha rhythm characterises a
dominance of ``top-down" processing in the absence of any external
stimulation (\cite{stein2000a}, see \cite{palva2007a} for a general
review).  Although the results here span a frequency band too broad to
compare to the classical alpha band (8-13 Hz), our results fit with the
idling hypothesis account, as stimulation strength anti-correlates with
alpha power, with stronger input leading to reduced alpha oscillations. The
anti-correlation found here does not show any modulation by auditory input,
so we assume that the spectrotemporal locking we have observed is a purely
visual phenomenon.



Overall, the effect sizes found using the spectrotemporal approach were
small. These correlations are calculated using total power, which includes
both induced (not phase-locked to stimulus onset) and evoked (phase-locked
to stimulus onset) components \citep{tallon-baudry1999a}.  Evoked power
constitutes only a small part of total power \textemdash here approximately
15\% \textemdash so if the stimulus-locked power changes are indeed
consistent in their phase with respect to the stimulus dynamics, then the
stimulus-locking effect may be hidden in the total power. In comparison,
Kayser and K\"onig's  results were indeed larger, with correlations of
approximately 0.13 compared to our 0.01, but were based on intra-cranial
LFP measurements that do not suffer from the spatial smearing inherent in
EEG. 



The second approach we employed, waveform analysis, correlated ERP
waveforms with stimulus speed. Our results revealed locking to visual
stimulus dynamics, distributed across many measurement sites. An
examination of the characteristics of the correlation results suggests at
least two distinct locking mechanisms: one measured occipitally with a
positive correlation at a lag of 78 ms, interpreted as an early visual
process; and the other appearing at centro-parietal sites as positive
locking at lags of -60 and 390 ms, interpreted as later stages of visual
processing. A positive correlation indicates that the phase of the EEG
waveform is aligned to the dynamics of the stimulus at a given time lag,
however the relative magnitude of both signals also contributes to this
measure of locking and we cannot isolate the role of phase alignment from
the role of amplitude changes. As mentioned above, we can furthermore
specify that entrained frequencies must lie in the range contained in the
speed profiles of our stimuli (0.5-4 Hz). Although steady-state responses
are typically evoked using stimuli presented at higher, regular stimulation
frequencies, entrainment has also been observed for frequencies in the
delta range \citep{ding2006a}. Less regular stimulus trains jittered in
time within this frequency range have also been found to have an
entrainment effect on visual and auditory cortex, which has been shown to
be the result of an instantaneous phase reset of the ongoing oscillatory
activity \citep{lakatos2008a, lakatos2005a}. Hence, we assume that in the
case of our much more irregular stimuli, faster visual input leads to a
stronger phase-reset across a large population of neurons, and thus to
stronger EEG amplitude that is phase-aligned with the stimulus.
Furthermore, we found that entrainment to visual stimuli increased over
stimulus duration at occipital sites, indicating that phase alignment to
our stimuli is a gradual process \textemdash there is no instantaneous
phase reset.



The role of ongoing neural oscillations has been emphasised in multisensory
research, in particular frequencies in the gamma range (see
\cite{senkowski2008a} for a recent review). The entrainment of lower
frequency oscillations, which are of particular interest here due to our
choice of stimuli, has also been implicated in multisensory processes. In
auditory cortex, the phase of all ongoing neuronal oscillations has been
proposed to be reset by tactile or visual input, with this general phase
reset hypothesised to allow more effective processing of subsequent
auditory signals arriving at an optimal phase of this reset activity
\citep{lakatos2007a, kayser2008a}. Such a mechanism has also been proposed
to be useful for audiovisual speech, with the regularities of the visual
input allowing a facilitation of temporally matched auditory input in noisy
backgrounds \citep{schroeder2008a}. In conclusion, crossmodal resetting of
cortical activity in a ``unimodal" area may allow prioritised processing of
temporally corresponding stimuli of the preferred modality, which would be
of great importance for multisensory processing.



Our waveform analysis results for audiovisual conditions can be related to
these findings. In general, we found stronger visual locking to congruent
than incongruent audiovisual stimuli. This difference in entrainment to
visual dynamics must be due to an effect of the auditory stimulus dynamics.
One possible interpretation is that congruently timed auditory stimulation
enhances the phase reset of visually entrained neurons. Furthermore, an
examination of the time course of the visual entrainment of waveforms
suggested two locking mechanisms, which seem to be differently involved in
multisensory processing when the entrainment to purely visual stimuli is
taken into account. The visual process measured at occipital sites shows a
continual increase in visual entrainment over the duration of unimodal
visual and congruent audiovisual stimulation, but a constant level of
entrainment for mismatched audiovisual inputs. As such, incongruent
auditory input seems to counteract visual entrainment, and the difference
in entrainment between congruent and incongruent conditions unfolds
gradually and slowly. The time course involved, in the magnitude of
seconds, is a strong indication that this process is initially driven by
bottom-up visual input, with information regarding multisensory congruence
arriving later, most likely via feedback from higher areas. Along these
lines, \cite{noesselt2007a} recently showed that modulations in primary
unisensory areas in response to temporally aligned audiovisual patterns
were a result of feedback from superior temporal sulcus. The visual locking
found here at centroparietal sites shows no change over time, with
congruent audiovisual input showing a clear advantage for locking over both
incongruent and unimodal visual stimulation. Thus, this process depends on
both input streams; however it is unclear whether this mechanism reflects
an evaluation of congruence or is itself the result of a match/mismatch
evaluation from elsewhere. Source analysis methods, and a direct evaluation
of the directional interaction between the two waveform locking mechanisms,
may help elucidate this in future work.



The behaviour of a dynamical system can be characterised by examining the
relationship between its output and a known input. Often-used inputs are of
two different kinds: impulses or continuous stimuli. In the case of a
linear system, these two inputs yield equivalent results. To date, sensory
processing has been analysed with an emphasis on this impulse-response
concept, specifically multimodal interaction (see \cite{calvert2004a} for a
general review of methodological approaches in multisensory research).
Here we want to fully exploit the high temporal resolution of EEG to
examine the nature of a temporal process, and it is rather the second kind
of input which is of interest. The present analysis amounts to an
investigation of the linearity of the audiovisual interactions. Indeed, the
observation of a time-dependant increase in coupling in the bimodal
congruent condition and unimodal visual condition is difficult to reconcile
with a purely linear system. The characteristics of the stimuli and the
analysis methods used in this study are better suited to such
investigations regarding non-linear system behaviour than traditional
impulse response approaches.



The integration of two sensory sources critically depends on the
compatibility of the temporal dynamics of both information streams. We used
stimulus locking to extended stimuli with complex temporal profiles as a
tool to investigate multisensory interactions. Spectrotemporal locking
revealed a bottom-up, purely visual effect. In contrast, waveform locking
showed modulation by auditory congruency and a differential effect over
time. We thus propose that spectrotemporal and waveform locking reflect
different mechanisms involved in the processing of dynamic audiovisual
stimuli, and that these analysis approaches may prove useful in future
research.
